{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'confusion_matrix' from 'keras.metrics' (/Applications/anaconda3/lib/python3.8/site-packages/keras/metrics.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-9623cfaafa42>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapplications\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmobilenet_v2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;31m# from keras.applications import resnet50\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'confusion_matrix' from 'keras.metrics' (/Applications/anaconda3/lib/python3.8/site-packages/keras/metrics.py)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, roc_auc_score\n",
    "\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras import metrics\n",
    "from keras.utils import np_utils\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.models import Sequential\n",
    "from keras.applications import mobilenet_v2\n",
    "# from keras.metrics import confusion_matrix\n",
    "# from keras.applications import resnet50\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.layers import ZeroPadding2D, Dropout, Dense, Conv2D, MaxPooling2D, Flatten, GlobalAveragePooling2D, InputLayer\n",
    "\n",
    "from keras_visualizer import visualizer \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Image</th>\n",
       "      <th>Drug</th>\n",
       "      <th>Compound MoA</th>\n",
       "      <th>Compound Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>11340528</td>\n",
       "      <td>Huperzine A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Huperzine A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>11340529</td>\n",
       "      <td>Huperzine A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Huperzine A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>11340530</td>\n",
       "      <td>Huperzine A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Huperzine A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>11340525</td>\n",
       "      <td>nalbuphine</td>\n",
       "      <td>GPCR agonist</td>\n",
       "      <td>nalbuphine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>11340526</td>\n",
       "      <td>nalbuphine</td>\n",
       "      <td>GPCR agonist</td>\n",
       "      <td>nalbuphine</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0     Image         Drug  Compound MoA Compound Name\n",
       "0           0  11340528  Huperzine A           NaN   Huperzine A\n",
       "1           1  11340529  Huperzine A           NaN   Huperzine A\n",
       "2           2  11340530  Huperzine A           NaN   Huperzine A\n",
       "3           3  11340525   nalbuphine  GPCR agonist    nalbuphine\n",
       "4           4  11340526   nalbuphine  GPCR agonist    nalbuphine"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_image_MoA = pd.read_csv('df_image_MoA.csv')\n",
    "df_image_MoA.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Kinase inhibitor       2930\n",
       "Chromatin structure    1782\n",
       "GPCR agonist           1641\n",
       "GPCR antagonist        1437\n",
       "Channel blocker        1161\n",
       "Name: Compound MoA, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_image_MoA['Compound MoA'].value_counts().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up data input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare images by converting PNGs to arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_image(img_path):\n",
    "    \"\"\" Takes in an image number, loads the png, and converts to array\"\"\"\n",
    "    try:        \n",
    "        img = image.load_img('raw_images/'+str(img_path)+'.png', target_size=(224, 224))\n",
    "    except: \n",
    "        print(img_path)\n",
    "    else:\n",
    "        x = image.img_to_array(img)\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "        x = mobilenet_v2.preprocess_input(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get list of images\n",
    "image_list = list(df_image_MoA.Image)\n",
    "\n",
    "# Loop through images and collect processed arrays into list\n",
    "array_list = []\n",
    "for image_ in image_list:\n",
    "    array_list.append(prepare_image(image_))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_array = np.vstack(array_list[0:25998])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('image_array', image_array, allow_pickle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_array = np.load('image_array.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the y-target (mechanism of action) of interest and create train-val-test splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Methods used for test-train split\n",
    "1. sklearn train-test split, Keras validation split\n",
    "    - Keras only takes the last part of data, does not shuffle\n",
    "2. sklearn train-test split, sklearrn train-validation split\n",
    "    - Uneven number of target and non-target class\n",
    "3. Stratify the train-test split and train-validation split\n",
    "    - Equal number of target and non-target class "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Methods used for category encodin\n",
    "1. One-hot encoding using np_utils.to_categorical\n",
    "    - Creates an (x,2) array \n",
    "    - Resulted in having an equal number of true positives and true negatives in the validation data. \n",
    "    - True positives + false positives = total data set\n",
    "2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_MoA(MoA):\n",
    "    \"\"\"Returns train-test split stratified on target class(MoA)\"\"\"    \n",
    "    df_image_MoA['Category'] = np.where(df_image_MoA['Compound MoA'] == MoA, 1, 0)\n",
    "    \n",
    "    # Assign X and y \n",
    "    X_ = image_array\n",
    "    y_ = df_image_MoA['Category'][0:25998]\n",
    "\n",
    "    # Train-test split\n",
    "    X_train_, X_test, y_train_, y_test = (train_test_split(X_, y_, \n",
    "                                                     test_size = .2, random_state = 22, stratify = y_))\n",
    "    y_test = y_test.astype('float32')\n",
    "    \n",
    "    X_train, X_valid, y_train, y_valid = (train_test_split(X_train_, y_train_, \n",
    "                                                     test_size = .25, random_state = 22, stratify = y_train_))\n",
    "    \n",
    "    y_train = y_train.astype('float32')\n",
    "    y_valid = y_valid.astype('float32')\n",
    "    return X_train, y_train, X_test, y_test, X_valid, y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, y_train_cat, X_test, y_test_cat, X_valid, y_valid_cat = get_MoA('Chromatin structure')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the shape of each split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to convert y labels from series to numpy arrays\n",
    "y_test_array = y_test_cat.to_numpy()\n",
    "y_train_array = y_train_cat.to_numpy()\n",
    "y_valid_array = y_valid_cat.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test different hyperparameters on a CNN\n",
    "\n",
    "### First set of overnight experiments\n",
    "#### CNN models from scratch\n",
    "1. NN_scratch - initial attempt\n",
    "    - Did not do better than chance, overfit immediately\n",
    "2. NN_scratch1 - add convolution layer\n",
    "    - Did not do better than chance\n",
    "3. NN_scratch2 - add dense layer \n",
    "    - Did not do better than chance\n",
    "4. NN_scratch3 - change activation functions from ReLU to LeakyReLU\n",
    "    - This helped very slightly\n",
    "\n",
    "#### CNN models with transfer learning\n",
    " 6. NN_trans - mobilenet2 pre-trained model\n",
    "    - No better than chance\n",
    " 7. NN_trans - resnet50 pre-trained model\n",
    "    - No better than chance\n",
    "    \n",
    "### Second set of experiments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard = TensorBoard(log_dir = 'logs/NN_scratch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_ = [metrics.AUC(curve='ROC'), metrics.AUC(curve = 'PR'), metrics.Recall(), metrics.Precision(), metrics.PrecisionAtRecall(0.5), metrics.TruePositives(), metrics.TrueNegatives(), metrics.FalseNegatives(), metrics.FalsePositives()]\n",
    "class_weights = {0:1, 1:15}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = {0:1, 1:15}\n",
    "NN_scratch = Sequential(\n",
    "                        [InputLayer(input_shape=X_train.shape[1:]),\n",
    "                         Conv2D(filters=32, kernel_size=3, activation='relu', padding='same'),\n",
    "                         MaxPooling2D(),\n",
    "                         Conv2D(filters=64, kernel_size=3, activation='relu', padding='same'),\n",
    "                         MaxPooling2D(),\n",
    "                         Flatten(),\n",
    "                         Dense(32, activation='relu'),\n",
    "                         Dropout(0.20),\n",
    "                         Dense(1, activation='sigmoid')]\n",
    "                       )\n",
    "\n",
    "NN_scratch.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics = metrics_,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "156/156 [==============================] - 395s 3s/step - loss: 1.2918 - auc: 0.6435 - auc_1: 0.1242 - recall: 0.8101 - precision: 0.0866 - precision_at_recall: 0.1040 - true_positives: 866.0000 - true_negatives: 5396.0000 - false_negatives: 203.0000 - false_positives: 9133.0000 - val_loss: 0.6755 - val_auc: 0.4883 - val_auc_1: 0.0673 - val_recall: 0.5266 - val_precision: 0.0632 - val_precision_at_recall: 0.0703 - val_true_positives: 188.0000 - val_true_negatives: 2055.0000 - val_false_negatives: 169.0000 - val_false_positives: 2788.0000\n",
      "Epoch 2/10\n",
      "156/156 [==============================] - 392s 3s/step - loss: 1.1228 - auc: 0.7689 - auc_1: 0.2618 - recall: 0.7577 - precision: 0.1210 - precision_at_recall: 0.2042 - true_positives: 810.0000 - true_negatives: 8643.0000 - false_negatives: 259.0000 - false_positives: 5886.0000 - val_loss: 0.7234 - val_auc: 0.4931 - val_auc_1: 0.0692 - val_recall: 0.5826 - val_precision: 0.0631 - val_precision_at_recall: 0.0701 - val_true_positives: 208.0000 - val_true_negatives: 1755.0000 - val_false_negatives: 149.0000 - val_false_positives: 3088.0000\n",
      "Epoch 3/10\n",
      "156/156 [==============================] - 393s 3s/step - loss: 0.8574 - auc: 0.8790 - auc_1: 0.4953 - recall: 0.8326 - precision: 0.1813 - precision_at_recall: 0.4677 - true_positives: 890.0000 - true_negatives: 10511.0000 - false_negatives: 179.0000 - false_positives: 4018.0000 - val_loss: 0.4612 - val_auc: 0.4836 - val_auc_1: 0.0693 - val_recall: 0.1092 - val_precision: 0.0746 - val_precision_at_recall: 0.0705 - val_true_positives: 39.0000 - val_true_negatives: 4359.0000 - val_false_negatives: 318.0000 - val_false_positives: 484.0000\n",
      "Epoch 4/10\n",
      "156/156 [==============================] - 377s 2s/step - loss: 0.7384 - auc: 0.9213 - auc_1: 0.6467 - recall: 0.8354 - precision: 0.2648 - precision_at_recall: 0.7098 - true_positives: 893.0000 - true_negatives: 12050.0000 - false_negatives: 176.0000 - false_positives: 2479.0000 - val_loss: 0.5521 - val_auc: 0.4932 - val_auc_1: 0.0734 - val_recall: 0.1765 - val_precision: 0.0797 - val_precision_at_recall: 0.0690 - val_true_positives: 63.0000 - val_true_negatives: 4116.0000 - val_false_negatives: 294.0000 - val_false_positives: 727.0000\n",
      "Epoch 5/10\n",
      "156/156 [==============================] - 374s 2s/step - loss: 0.4975 - auc: 0.9613 - auc_1: 0.7998 - recall: 0.8653 - precision: 0.3880 - precision_at_recall: 0.9036 - true_positives: 925.0000 - true_negatives: 13070.0000 - false_negatives: 144.0000 - false_positives: 1459.0000 - val_loss: 0.5205 - val_auc: 0.4934 - val_auc_1: 0.0725 - val_recall: 0.1064 - val_precision: 0.0812 - val_precision_at_recall: 0.0687 - val_true_positives: 38.0000 - val_true_negatives: 4413.0000 - val_false_negatives: 319.0000 - val_false_positives: 430.0000\n",
      "Epoch 6/10\n",
      "156/156 [==============================] - 400s 3s/step - loss: 0.3588 - auc: 0.9804 - auc_1: 0.8834 - recall: 0.8962 - precision: 0.4795 - precision_at_recall: 0.9796 - true_positives: 958.0000 - true_negatives: 13489.0000 - false_negatives: 111.0000 - false_positives: 1040.0000 - val_loss: 0.5906 - val_auc: 0.4868 - val_auc_1: 0.0752 - val_recall: 0.0700 - val_precision: 0.0799 - val_precision_at_recall: 0.0687 - val_true_positives: 25.0000 - val_true_negatives: 4555.0000 - val_false_negatives: 332.0000 - val_false_positives: 288.0000\n",
      "Epoch 7/10\n",
      "156/156 [==============================] - 381s 2s/step - loss: 0.3469 - auc: 0.9807 - auc_1: 0.8989 - recall: 0.8980 - precision: 0.5021 - precision_at_recall: 0.9910 - true_positives: 960.0000 - true_negatives: 13577.0000 - false_negatives: 109.0000 - false_positives: 952.0000 - val_loss: 0.5865 - val_auc: 0.4789 - val_auc_1: 0.0702 - val_recall: 0.0728 - val_precision: 0.0672 - val_precision_at_recall: 0.0687 - val_true_positives: 26.0000 - val_true_negatives: 4482.0000 - val_false_negatives: 331.0000 - val_false_positives: 361.0000\n",
      "Epoch 8/10\n",
      "156/156 [==============================] - 371s 2s/step - loss: 0.2810 - auc: 0.9866 - auc_1: 0.9217 - recall: 0.9074 - precision: 0.5584 - precision_at_recall: 0.9949 - true_positives: 970.0000 - true_negatives: 13762.0000 - false_negatives: 99.0000 - false_positives: 767.0000 - val_loss: 0.6902 - val_auc: 0.4869 - val_auc_1: 0.0701 - val_recall: 0.0476 - val_precision: 0.0683 - val_precision_at_recall: 0.0688 - val_true_positives: 17.0000 - val_true_negatives: 4611.0000 - val_false_negatives: 340.0000 - val_false_positives: 232.0000\n",
      "Epoch 9/10\n",
      "156/156 [==============================] - 365s 2s/step - loss: 0.2466 - auc: 0.9893 - auc_1: 0.9366 - recall: 0.9224 - precision: 0.5515 - precision_at_recall: 0.9987 - true_positives: 986.0000 - true_negatives: 13727.0000 - false_negatives: 83.0000 - false_positives: 802.0000 - val_loss: 0.7085 - val_auc: 0.4855 - val_auc_1: 0.0697 - val_recall: 0.0700 - val_precision: 0.0710 - val_precision_at_recall: 0.0688 - val_true_positives: 25.0000 - val_true_negatives: 4516.0000 - val_false_negatives: 332.0000 - val_false_positives: 327.0000\n",
      "Epoch 10/10\n",
      "156/156 [==============================] - 344s 2s/step - loss: 0.2583 - auc: 0.9881 - auc_1: 0.9360 - recall: 0.9130 - precision: 0.5527 - precision_at_recall: 1.0000 - true_positives: 976.0000 - true_negatives: 13739.0000 - false_negatives: 93.0000 - false_positives: 790.0000 - val_loss: 0.6816 - val_auc: 0.4927 - val_auc_1: 0.0734 - val_recall: 0.0756 - val_precision: 0.0718 - val_precision_at_recall: 0.0688 - val_true_positives: 27.0000 - val_true_negatives: 4494.0000 - val_false_negatives: 330.0000 - val_false_positives: 349.0000\n"
     ]
    }
   ],
   "source": [
    "NN_scratch_model = NN_scratch.fit(X_train, y_train_array, epochs=10, verbose=1, batch_size = 100, class_weight = class_weights, validation_data = (X_valid, y_valid_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163/163 [==============================] - 35s 198ms/step - loss: 0.6555 - auc: 0.5248 - auc_1: 0.0727 - recall: 0.0730 - precision: 0.0684 - precision_at_recall: 0.0752 - true_positives: 26.0000 - true_negatives: 4490.0000 - false_negatives: 330.0000 - false_positives: 354.0000\n",
      "[0.6554743647575378, 0.5248062610626221, 0.07273760437965393, 0.07303370535373688, 0.06842105090618134, 0.0751708447933197, 26.0, 4490.0, 330.0, 354.0]\n"
     ]
    }
   ],
   "source": [
    "results = NN_scratch.evaluate(X_test, y_test_cat)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9315384615384615"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test_array, np.argmax(NN_scratch.predict(X_test), axis = -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_test_array, np.argmax(NN_scratch.predict(X_test), axis = -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test_array, np.argmax(NN_scratch.predict(X_test), axis = -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN_scratch.history.history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add a convolution filter of 128 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[4844,    0],\n",
       "       [ 356,    0]], dtype=int32)>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "conf_matrix = tf.math.confusion_matrix(labels=y_test_array,\n",
    "                                       predictions=NN_scratch.predict(X_test))\n",
    "conf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Add convolution filter\n",
    "\n",
    "NN_scratch1 = Sequential(\n",
    "                        [InputLayer(input_shape=X_train.shape[1:]),\n",
    "                         Conv2D(filters=32, kernel_size=3, activation='relu', padding='same'),\n",
    "                         MaxPooling2D(),\n",
    "                         Conv2D(filters=64, kernel_size=3, activation='relu', padding='same'),\n",
    "                         MaxPooling2D(),\n",
    "                         Conv2D(filters=128, kernel_size=3, activation='relu', padding='same'),\n",
    "                         MaxPooling2D(),\n",
    "                         Flatten(),\n",
    "                         Dense(32, activation='relu'),\n",
    "                         Dropout(0.20),\n",
    "                         Dense(1, activation='sigmoid')]\n",
    "                       )\n",
    "\n",
    "NN_scratch1.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=metrics_,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " 38/125 [========>.....................] - ETA: 4:12 - loss: 2.1853 - auc: 0.5073 - auc_1: 0.0710 - recall: 0.2110 - precision: 0.0678 - precision_at_recall: 0.0703 - true_positives: 105.2105 - true_negatives: 5194.3947 - false_negatives: 379.1316 - false_positives: 1471.2632"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-8d711a49ac83>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m NN_scratch1.fit(X_train, y_train_array, epochs=10, verbose=1, batch_size = 100, validation_split=0.2, class_weight = class_weights, validation_data = (X_valid, y_valid_array), callbacks=[\n\u001b[0m\u001b[1;32m      2\u001b[0m         keras.callbacks.EarlyStopping(patience=8, verbose=1, restore_best_weights=True)])\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1156\u001b[0m                 _r=1):\n\u001b[1;32m   1157\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1158\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1159\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3021\u001b[0m       (graph_function,\n\u001b[1;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3023\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3024\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1958\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1959\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1960\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1961\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    589\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "NN_scratch1.fit(X_train, y_train_array, epochs=10, verbose=1, batch_size = 100, validation_split=0.2, class_weight = class_weights, validation_data = (X_valid, y_valid_array), callbacks=[\n",
    "        keras.callbacks.EarlyStopping(patience=8, verbose=1, restore_best_weights=True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = NN_scratch1.evaluate(X_test, y_test_array)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "accuracy_score(y_test_array, np.argmax(NN_scratch1.predict(X_test), axis = -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_score(y_test_array, np.argmax(NN_scratch1.predict(X_test), axis = -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(y_test_array, np.argmax(NN_scratch1.predict(X_test), axis = -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add a dense layer of 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add dense layer \n",
    "\n",
    "NN_scratch2 = Sequential(\n",
    "                        [InputLayer(input_shape=X_train.shape[1:]),\n",
    "                         Conv2D(filters=32, kernel_size=3, activation='relu', padding='same'),\n",
    "                         MaxPooling2D(),\n",
    "                         Conv2D(filters=64, kernel_size=3, activation='relu', padding='same'),\n",
    "                         MaxPooling2D(),\n",
    "                         Flatten(),\n",
    "                         Dense(32, activation='relu'),\n",
    "                         Dense(16, activation='relu'),\n",
    "                         Dropout(0.20),\n",
    "                         Dense(1, activation='sigmoid')]\n",
    "                       )\n",
    "\n",
    "\n",
    "NN_scratch2.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=metrics_,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NN_scratch2.fit(X_train, y_train_array, epochs=10, verbose=1, batch_size = 100, class_weight = class_weights, validation_data = (X_valid, y_valid_array), callbacks=[\n",
    "        keras.callbacks.EarlyStopping(patience=8, verbose=1, restore_best_weights=True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = NN_scratch2.evaluate(X_test, y_test_array)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test_array, np.argmax(NN_scratch2.predict(X_test), axis = -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_score(y_test_array, np.argmax(NN_scratch2.predict(X_test), axis = -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(y_test_array, np.argmax(NN_scratch2.predict(X_test), axis = -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change relu activation to leaky relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NN_scratch3 = Sequential(\n",
    "                        [InputLayer(input_shape=X_train.shape[1:]),\n",
    "                         Conv2D(filters=32, kernel_size=3, activation=LeakyReLU(alpha = 0.20), padding='same'),\n",
    "                         MaxPooling2D(),\n",
    "                         Conv2D(filters=64, kernel_size=3, activation=LeakyReLU(alpha = 0.20), padding='same'),\n",
    "                         MaxPooling2D(),\n",
    "                         Flatten(),\n",
    "                         Dense(32, activation =  LeakyReLU(alpha=0.20)),\n",
    "                         Dropout(0.20),\n",
    "                         Dense(1, activation='sigmoid')]\n",
    "                       )\n",
    "\n",
    "NN_scratch3.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=metrics_,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NN_scratch3.fit(X_train, y_train_array, epochs=10, verbose=1, batch_size = 100, class_weight = class_weights, validation_data = (X_valid, y_valid_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = NN_scratch3.evaluate(X_test, y_test_array)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test_array, np.argmax(NN_scratch3.predict(X_test), axis = -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_score(y_test_array, np.argmax(NN_scratch3.predict(X_test), axis = -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(y_test_array, np.argmax(NN_scratch3.predict(X_test), axis = -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set class weights to be balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NN_scratch4 = Sequential(\n",
    "                        [InputLayer(input_shape=X_train.shape[1:]),\n",
    "                         Conv2D(filters=32, kernel_size=3, activation=LeakyReLU(alpha = 0.20), padding='same'),\n",
    "                         MaxPooling2D(),\n",
    "                         Conv2D(filters=64, kernel_size=3, activation=LeakyReLU(alpha = 0.20), padding='same'),\n",
    "                         MaxPooling2D(),\n",
    "                         Flatten(),\n",
    "                         Dense(32, activation =  LeakyReLU(alpha=0.20)),            \n",
    "                         Dense(1, activation='sigmoid')]\n",
    "                       )\n",
    "\n",
    "NN_scratch4.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=metrics_,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = NN_scratch4.evaluate(X_test, y_test_array)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test_array, np.argmax(NN_scratch4.predict(X_test), axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_score(y_test_array, np.argmax(NN_scratch4.predict(X_test), axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(y_test_array, np.argmax(NN_scratch4.predict(X_test), axis = 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NN_transfer - try out pre-trained models. First try MobilNetV2. Interestingly, MobileNet believes that fluorscent cell images are mostly objects found in the ocean. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = mobilenet_v2.MobileNetV2(weights='imagenet',)\n",
    "\n",
    "for img_ in image_array[10:15]:\n",
    "    out = model.predict(img_)\n",
    "    print('Predicted:', mobilenet_v2.decode_predictions(out))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transfer learning with mobilenetv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard = TensorBoard(log_dir = 'logs/NN_transfer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exclude the final dense layers by setting include_top=False, and add new ones to train from scratch below\n",
    "base_model = mobilenet_v2.MobileNetV2(weights='imagenet', include_top=False, input_shape=(228,228,3)) \n",
    "\n",
    "# Freeze convolutional layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False    \n",
    "    \n",
    "# Establish new fully connected block\n",
    "NN_transfer = Sequential(\n",
    "                        [InputLayer(input_shape=X_train.shape[1:]),\n",
    "                         ZeroPadding2D(padding=2),\n",
    "                         base_model,\n",
    "                         Flatten(),\n",
    "                         Dense(32, activation='relu'),\n",
    "                         Dropout(0.20),\n",
    "                         Dense(1, activation='sigmoid')]\n",
    "                       )\n",
    "\n",
    "NN_transfer.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=metrics_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NN_transfer.fit(X_train, y_train_array, epochs=10, verbose=1, batch_size = 100, validation_data = (X_valid, y_valid_array), class_weight = class_weights, callbacks = [tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = NN_transfer.evaluate(X_test, y_test_array)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test_array, np.argmax(NN_transfer.predict(X_test), axis = -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_score(y_test_array, np.argmax(NN_transfer.predict(X_test), axis = -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(y_test_array, np.argmax(NN_transfer.predict(X_test), axis = -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "history = NN_transfer.history\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.ylim(bottom = 0)\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.savefig('best_loss.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "history = NN_transfer.history\n",
    "plt.plot(history.history['auc_3'])\n",
    "plt.plot(history.history['val_auc_3'])\n",
    "plt.ylim(bottom = 0)\n",
    "plt.title('model AUC-PR')\n",
    "plt.ylabel('AUC-PR')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.savefig('best_AUC-PR.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(\n",
    "    NN_transfer,\n",
    "    to_file=\"model.png\",\n",
    "    show_shapes=False,\n",
    "    show_dtype=False,\n",
    "    show_layer_names=True,\n",
    "    rankdir=\"TB\",\n",
    "    expand_nested=False,\n",
    "    dpi=96,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now try resnet50 as pre-trained model, ended it because it was slow and not learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exclude the final dense layers by setting include_top=False, and add new ones to train from scratch below\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(228,228,3)) \n",
    "\n",
    "# Freeze convolutional layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False    \n",
    "    \n",
    "# Establish new fully connected block\n",
    "NN_transfer1 = Sequential(\n",
    "                        [InputLayer(input_shape=X_train.shape[1:]),\n",
    "                         ZeroPadding2D(padding=2),\n",
    "                         base_model,\n",
    "                         Flatten(),\n",
    "                         Dense(32, activation='relu'),\n",
    "                         Dense(1, activation='sigmoid')]\n",
    "                       )\n",
    "\n",
    "NN_transfer1.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=metrics_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NN_transfer1.fit(X_train, y_train_array, epochs=10, verbose=1, batch_size = 100, validation_data = (X_valid, y_valid_array), class_weight=class_weights, callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test, np.argmax(NN_transfer1.predict(X_test), axis = -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_score(y_test, np.argmax(NN_transfer1.predict(X_test), axis = -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(y_test, np.argmax(NN_transfer1.predict(X_test), axis = -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "history = NN_scratch3.history\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.ylim(bottom = 0)\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.savefig('best_loss.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'loss'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-a6975e243b58>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# history = NN_scratch.history\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNN_scratch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbottom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'loss'"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "# history = NN_scratch.history\n",
    "plt.plot(NN_scratch.history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.ylim(bottom = 0)\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.savefig('best_loss.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN_scratch.history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
